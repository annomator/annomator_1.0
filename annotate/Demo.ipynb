{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annomator Demo\n",
    "### V 0.1 Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annomator comes with three distinct parts:\n",
    "1  Automatic annotator that can turn your pictures into text\n",
    "2  Trainers for boxes and masks\n",
    "3  A slice of TF OD to make setup easier for some\n",
    "\n",
    "Compatible with Linux, Windows and Mac, TF 1.5 and 1.8 models, Python 2 and 3, CPU or GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may be able to use the annomator with your existing Tensorflow install or use\n",
    "pip install -r annotator_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Object Detection API\n",
    "Creating accurate machine learning models capable of localizing and identifying\n",
    "multiple objects in a single image remains a core challenge in computer vision.\n",
    "The TensorFlow Object Detection API is an open source framework built on top of\n",
    "TensorFlow that makes it easy to construct, train and deploy object detection\n",
    "models.  At Google weâ€™ve certainly found this codebase to be useful for our\n",
    "computer vision needs, and we hope that you will as well.\n",
    "<p align=\"center\">\n",
    "  <img src=\"g3doc/img/kites_detections_output.jpg\" width=676 height=450>\n",
    "</p>\n",
    "Contributions to the codebase are welcome and we would love to hear back from\n",
    "you if you find this API useful.  Finally if you use the Tensorflow Object\n",
    "Detection API for a research publication, please consider citing:\n",
    "\n",
    "```\n",
    "\"Speed/accuracy trade-offs for modern convolutional object detectors.\"\n",
    "Huang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I, Wojna Z,\n",
    "Song Y, Guadarrama S, Murphy K, CVPR 2017\n",
    "```\n",
    "\\[[link](https://arxiv.org/abs/1611.10012)\\]\\[[bibtex](\n",
    "https://scholar.googleusercontent.com/scholar.bib?q=info:l291WsrB-hQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWUIIlnPZ_L9jxvPwcC49kDlELtaeIyU-&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1)\\]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"g3doc/img/tf-od-api-logo.png\" width=140 height=195>\n",
    "</p>\n",
    "\n",
    "## Maintainers\n",
    "\n",
    "* Jonathan Huang, github: [jch1](https://github.com/jch1)\n",
    "* Vivek Rathod, github: [tombstone](https://github.com/tombstone)\n",
    "* Ronny Votel, github: [ronnyvotel](https://github.com/ronnyvotel)\n",
    "* Derek Chow, github: [derekjchow](https://github.com/derekjchow)\n",
    "* Chen Sun, github: [jesu9](https://github.com/jesu9)\n",
    "* Menglong Zhu, github: [dreamdragon](https://github.com/dreamdragon)\n",
    "* Alireza Fathi, github: [afathi3](https://github.com/afathi3)\n",
    "* Zhichao Lu, github: [pkulzc](https://github.com/pkulzc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annomator is an automated annotator and trainer based on Tensorflow (TF) 1.5.0 and Object Detection (OD) API 1.0.  It has primarily been designed for researchers but others may find it useful.  I have no affiliations or endorsement from anyone but hope it helps others.  \n",
    "\n",
    "Despite the name, this is just a personal site of one person.  I do not profit or receive anything but bug reports and criticism so please be patient.  I will eventually respond to annomator@gmail.com\n",
    "\n",
    "In short, you can blame me (but not sue me) for all the sloppy code.  \n",
    "You can thank Tesorflow, Slim and Object Detection for all the technology and the functionality.  I don't claim to have done anything tried to make it easier to use and add a codecs.\n",
    "\n",
    "I have a simple terminal script and a jupyter notebook to help install.  Mac and Linux will have to run one more line but the rest is setup for annotating.  This will essentially turn pictures into text in a way you can use.  I have also included code for training boxes or masks with your own data so you can search and analyse the results yourself.  \n",
    "\n",
    "With the latest release (September 2018) of TF OD making code breaking changes I have decided to release this as a standalone tangent based on TF 1.5.0 the earlier OD.  Testing TF 1.10 and latest OD still has too many bugs for many.  After spending a week with the new version I am not going to try moving anyone else to 1.10 as there are still too many cross-platform issues.  \n",
    "\n",
    "Annotator is primarily aimed at researchers that have failed to get the official version working.  The code is compatible with official install so anyone who is confident can move to the latest versions with a few minor alterations.  \n",
    "\n",
    "Anyone who simply wants to identify and count from images may find it useful.  Slides, transects, maps  or any image can be annotated and then analysed.  I assume there are many others who may not have access to a good linux computer, internet access or cloud time who may benefit.  \n",
    "\n",
    "It is only because I am humbled by good people doing good research.\n",
    "\n",
    "Evil needs only\n",
    "Edmond Burke\n",
    "\n",
    "There is one man who has flown the length of the country for years counting birds from a small plane and identifying birds at an auction-like pace.  It has finally been transcribed and is still one of the best indicators we have of the health of the Murray-Darling River System.  This wouldn't be worth mentioning at all if there wasn't billions of dollars set aside to find a healthy comprimise between the farmers, citizens and the environment.  For the hard work of Richard Kingsford, I hope it helps count birds or dams or makes it easier to gather the data you need.  To whoever did the transcribing, Tensorflow does audio too.  In fact, the citizens and scientists have already developed a frog identification application for Australia based on Tensorflow and audio recognition.  \n",
    "\n",
    "For Ian Frazer counting cells and devloping the cervical cancer vaccine.  For Ove Hoegh-Guldberg and his work on coral reefs.  For John Sinclair, Robert Whyte and Sheldon Navie, this is for your self-sacrifice in the search for truth.  37 new spiders were found in September 2018 alone.  \n",
    "\n",
    "One thing we don't have good, cheap internet.  The assistant treasurer was just forced to pay back $3000 for one month.  Seems outrageous until you realise that, like me, he was forced to run his home from the 4G mobile network.  At ~$10 gig you would only need to use 1 gb a day for his family house.  I have no reason to defend him and can only speculate but I have been in the same situation.  It was cheaper to buy a hard drive and have it delivered, then re-delivered by mail.  At ~$200 for 20gb it was much better than $2000 to download.\n",
    "\n",
    "It was cheaper for me to buy a new tb hard drive and have 20gb delivered\n",
    "\n",
    "Research funding is much lower (% GDP) and the brain drain to US has been prolific in the new wave of AI.  \n",
    "\n",
    "All of these things are happening within a few hours of where I live so I am sorry I cannot help everyone.  If you are researching or working with Australian species ID or biomedical I may be able to help.  Active NHMRC grants and WONS related will \n",
    "\n",
    "Once annotated, you can search by text or use spreadsheet and database for easy analysis.  \n",
    "\n",
    "Students of AI finding it hard to get started.  There are some helpful functions in the anno_repo folder that should help you train boxes and masks, json or png, condensed or binary...  You can try squeezing it all back on a phone or try the latest cutting edge nasnet.  \n",
    "\n",
    "Even if you just want to be able to search through 10 years of personal images for 'that day with the dog and the boat', this might be a good way to catalogue every picture you have ever taken.  Offline.\n",
    "\n",
    "Every output can be started and stopped.  All can be edited and rerun.   I have tried to make a version that will run on most computers.  Real world it should take from 1 sec to 10 minutes to annotate an image of 1024x1024 using a standard desktop.  The question is possibly how long does your computer sit idle?  8 hours? 16 hours?\n",
    "\n",
    "All the codecs can be used for training\n",
    "\n",
    "My personal contribution is the png condensed codecs.  I could not find anything that was easy that worked for masks.  I have made a number of codecs for use with everything from astronomy to microscopy.  Condensed masks (generally png) can encode the information in the red, green and blue of a way that can be seen and edited.  \n",
    "\n",
    "The binary format is not new but the other codecs but I am introducing are an 'Offset' codec for simple cases, 'Centric' is based around a foreground/background split such as objects/textures, 'Things' and 'Stuff' of MSCOCO Panoptic.  No xml, json, pbtxt or external text file needed.  \n",
    "\n",
    "All released codecs use the format\n",
    "Red = Category\n",
    "Green = Category Count\n",
    "Blue = Total Count\n",
    "\n",
    "I have others that I have removed and others I would like to add.  I am up looking for some early-adopter, casual-kagglers, tf slim and OD experts for OS specific support.  \n",
    "\n",
    "Annomator 1.0 comes setup with a novel condensed mask codec I have called Metric.  \n",
    "\n",
    "I have also included converters and trainers for MSCOCO Panoptic json and png.  No pycocotools needed but it is also compatible with MSCOCO API and MSCOCO Panoptic API's.\n",
    "\n",
    "I cannot help everyone, or convince anyone it is easy for non-coders to get running.  I have created this initially as an easy way for researchers to gather data from images.  This is simply a standard setup that is quick and easy for most users.  If you have followed this setup I can help you to do everything yourself.  \n",
    "\n",
    "\n",
    "From algae to blood cells there are many projects just locally that could benefit without leaving a lab.  Within a few hours of where I live there has been 27 new spider species discovered in September 2018, the cervical cancer vaccine was developed, and yet the net is terrible.  I had cheaper and better access last century.  The Australian assistant treasurer has just been forced to pay back $3000 bill for one month of internet access.  The real story is that he could not get access to our infamous National Broadband Network so he was forced to pay for 4G mobile access.  At ~$10/gig for his whole family household for one month being 30gb (pure speculation on his bill) but I have to say that is not too bad.  I can only confidently guess because I am in exactly the same situation.  The only shocking thing is that I had a better and cheaper internet connection last century.  \n",
    "\n",
    "It was actually cheaper for me to have 20gig data delivered to my door (~$200) on a hard drive than to download (~$2000).  Not Antarctica; Australia.  When fuel, net and computers are cheap and accessible, when you are sitting on a T1 with a linux with a 1080 with access to free cloud time and TPU's it all makes perfect sense.  \n",
    "\n",
    "When internet access is cheap and good, cloud computing is great, particularly when software cross-platform hardware is changeing so rapidly.  I assume there are many that don't have a decent linux setup with a nice 1080 or any chance of utilising cloud time on the other side of the planet.  I hope this helps.\n",
    "\n",
    "Please be aware that these are just a few things I would rather be doing than debugging\n",
    "The cure for cervical cancer was done in qld.  \n",
    "37 new spiders were just disovered\n",
    "billions are poised to be spent by the government on rivers to the east\n",
    "If it wasn't for the stiff-stomach of one person in a small plane we wouldn't know much about the health of the Murray-Darling River System.  It has only been transcribed in the last year.  Between the farmers, the government it is hard to defend what we know little about.  For the Richard Kingsford Smiths\n",
    "With the whales migrating past and 27 new species of spider being discovered I cannot do nothing... can I?  So what if they cured cervical cancer...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have included versions for three target audiences\n",
    "##### 1 Text - csv or txt - click to open on any platform - for non-coders\n",
    "##### 2 Boxes - json format - for traditional training\n",
    "##### 3 Masks - png masks from images you can start yourself and/or auto-annotate\n",
    "Coding directives\n",
    "Code for common operating systems.  Windows, Mac and Linux.\n",
    "Code for Python 2.7 to 3.6\n",
    "Code for Cuda 9 GPU's (tf 1.5.0 to 1.10 if not built from source)\n",
    "Code for local, not cloud or server so \n",
    "- variables over argparsing\n",
    "- four-space\n",
    "- python 3 and \n",
    "- common file and image manipulation use os and PIL over tf.gfile and server app argparsing etc\n",
    "All versions are coded to be able to stop and start, edit and mix results for new summaries.\n",
    "Code for low-end or mid-range hardware, rather than top-end.\n",
    "Code for 1.5.0 and 1.8.0 models\n",
    "Download should be ready to run and compatible (not tf server) with TF OD and slim.\n",
    "Disable auto-downloading gigs of superfluous files.  One can easily download files over 1GB using demo a beginner may even be oblivious until their net bill comes.  Easy to find at tf zoo, know size and make a conscious decision.  It may annoy a few to de-auto but may save many.  \n",
    "\n",
    "\n",
    "Some of us still pay circa $10 gig.  (Rural Aust)  Don't even mention the NBN.  Do mention the years of 4k video and pictures you have on a windows or mac.  Now tell me how can use python let alone json let alone tensorflow let alone compile.  Not many.  If any.  Now tell me how many have a cure for cancer that just needs some cell counts.  Have you actually discovered a new Australian Spider?  If only the invasive weeds could be tracked and energy directed where needed.  There are so many riteous causes that would otherwise find it hard to get started.\n",
    "\n",
    "Even my personal collection of images has become a mess of different devices.  I would love to separate my nature shots from my social pics.  Samsung, Windows, Mac all have a standard photo app and of course there is Facebook timeline.  The overlap being facetagging, resnet101 and MaskRCNN all have the same author.  One way to describe it is to have a private, offline, bandwidth free facetagger.  \n",
    "\n",
    "You can finally search for that day with the boat and the dog because you can finally search your pictures using text.  It goes both ways because now you can identify what is in a picture and then search for others like it as you have the text.  ie search by images.  \n",
    "\n",
    "This can also be folded back on itself by building a trainer from the results.  For example:  Identify a person or pet from images using a pretrained model.  Save these annotations as the name of the pet or person. eg foo  Now that you have changed the label to 'foo' you can annotate another example and label it 'bar'.  With ~100 images auto-annotated, you have the basis to train a new model.  \n",
    "\n",
    "Some on stackoverflow have been defeated getting TF OD working so this is also a \"demo for the defeated\" as you don't need to compile, setup, install, protos the protoc(?) or anything else.  It should work with any successful install 1.5.0 - 1.10 but I am only providing support for 1.5.0.  Don't use Python 3.7, Cuda 10 or TF 1.11 yet as still too edgy (Oct 2018)\n",
    "\n",
    "\n",
    "We don't all live in California, or even what a 1080 GPU might mean, let alone guess at cloud training or TPU's.  Is it really a Tensorflow or open source if most people can't access it?\n",
    "The folder structure and install is problematic.  If you follow the install and pets intro instructions to the letter you end up with a pip egg in situ and a mess you have to clean up. \n",
    "This may sound crazy but what about a demo (file demo, titled tutorial) that works.  Kinda like a working demo.  One that works...  Maybe not encourage them to github the whole repo...  Maybe just a 100mb to get it going... Ok... you have to get three copies? \n",
    "IF you get through the install, the steps to training make you want to go kiss keras.  All that said I have made a training module for those who want to train.  The advantage being is you can slide in the very latest releases for training and detection.  Download, paste, go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Annotate Text\n",
    "\n",
    "##### Target Audience: researchers, students, non-profit, non-coders and personal use.\n",
    "\n",
    "Click a csv on most computers with office (Open or MS) and it may just open in a spreadsheet.  It should at least be easy to import to spreadsheet or database and allow analysis from end-user.  \n",
    "You can edit individual text files of each image tested to confirm or correct\n",
    "Any previous detections are skipped and the text file is collected for a summary\n",
    "Visual images are also made to allow easy corrections - write notes on image or change text \n",
    "The visual is also available in png, jpg or pdf because...  well...  because you didn't want to hear about pngs...  or lossless formats...  or linux...  or compiling...  ever.\n",
    "Apparantly, seeing it at work or home, pc or phone, or online email is a thing people do.\n",
    "The primary objective is actually computer, field or lab so all joking aside, hand-held/OS compatibility is critical for students and researchers.\n",
    "\n",
    "No training is available from text files - see json boxes or png masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python annotate_text_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate json boxes\n",
    "This is designed for people who want to learn AI, Tensorflow Object Detection or train on boxed annotations or box models.  A json file (text) as an output is not easy extract data without writing a bit of python code but perfect for storing image and box data.  \n",
    "JSON is a standardised text format, primarily for storing data\n",
    "The category index is translated and included, as well as the detections\n",
    "It is hard to find or change data by hand but it is 'human-readable'\n",
    "It is often used to store training information for a boxes only model\n",
    "The majority of models at TF Model Zoo are only boxes and most are based on the MSCOCO Dataset\n",
    "\n",
    "Want a faster model? Want better model? No problem.  Just download, unzip the graph and go.\n",
    "As this has been covered elsewhere in more depth, I have included it for comparison and completion.\n",
    "\n",
    "A box trainer is included that can be trained from json (annotated or mscoco panoptic) or from png masks (color condensed or binary).  All MSCOCO box models on TF Zoo are compatible (1.5.0 and 1.8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python annotate_json_boxes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Masks\n",
    "Masks, or semantic encoding, involves categorizing down to pixel level\n",
    "Easy for the end-user but the coding gets a little tricky for beginners\n",
    "To pull this off you need to encode and decode the information in the color\n",
    "You then want to see that code through a bit of math magic\n",
    "For the end-user it is easy.  You can just use the dropper chart and an image copy.\n",
    "You can also race through and auto-encode category, counts, totals into the color.\n",
    "The aim, in this case, is not to 'color-in' well but to identify correctly and fast.\n",
    "- see unet if you want to color-in well\n",
    "Many will be usable for training directly, or annotate every pixel.\n",
    "Others will need more work before training but this all depends on the settings and images.\n",
    "I have included four distinct codecs for discussion and use.  \n",
    "\n",
    "A box trainer is included that can be trained from png masks.  There are four flavours released for discussion and use:  Offset, Centric, Metric and Binary\n",
    "\n",
    "So far I have not released the 255+ codecs as the project has already reached a level of complexity that would suit most end users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python annotate_png_masks.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And still there is more.  All of the codecs and models can be used for training too.  I have included a Tf Record Maker for boxes and masks that has all the bells and whistles.  You can resize pictures, sample classes and create TF Records for box or mask models with randomised splits.  The MSCOCO Panoptic Classes are covered and any model up to 254 classes can be easily implimented.  \n",
    "\n",
    "There is no json or xml needed.  I have also exlcuded pycocotools entirely for the first version, which only removes the eval.py script from working.  Coco metric will not work but it does not affect the Tensorboard training statistics so does not affect the training pipeline.  Kagglers (AI Competitors), professionals and others will no doubt want eval, mAP etc and Run Length Encoding.  The project remains fully compatible with pycocotools, including the panoptic api version, so install if you can already compile C++ you should be able to get eval and rle working.  If there is enough requests, I can implement the eval without pycocotools, other metrics, or add RLE to the standard codecs.\n",
    "\n",
    "The real issue is may possibly the giant mess of trying to get pycocotools working for Windows has turned many off.  If you already have Visual Studio, the smaller packages may not work.  You may need to sign up to get a microsoft account, get gigs of Visual Studio update, then get the C++ for python.  At this point you would still need to download the right protoc and again, despite instructions, individually protoc files just to get the demo working.  You can now translate label.pbtxt.  Now you need me to tell you what the maximum class id is? and put it in the NUM_CLASSES?  Fails to train using python 3.  Following the instructions just left a trail of tf\\models\\research\\python egg buried in sea of things I will never use.  I see they have simply not included Windows instructions in the latest version at all, but insist you need Python 3 and TF 1.9+.  If I read another line about AVX being the issue I will lose my shit.  Lets all play nice.  \n",
    "\n",
    "This version is not designed for production.  This version is not server ready or cloud ready.  \n",
    "Please use the official version and installation instructions.\n",
    "\n",
    "I have made a few coding choices to make it simpler for beginners and non-coders\n",
    "- Use of variables over argparsing\n",
    "- Use of common file and image over tf.gfile etc\n",
    "- I have added functions to make customizing simpler\n",
    "\n",
    "Use the official version if you want to run on a server.  See official instructions if you want to use cloud computing.  \n",
    "\n",
    "I also have to add the disclaimer that this has been version has primarily been designed for researchers, students and personal use.  It is not suitable for critical systems or production.  That said, it is largely unchanged and written to be completely compatible with the latest versions and cutting edge models.\n",
    "\n",
    "My version will stay true to 1.5.0 Version until at least June 2019.  You can still build from source and use any version but I have there has not been version since that will work on all platforms without compiling from source.  If you don't know what TF 1.7+ or Keras sugar you are missing out on then this is probably the version for you.  \n",
    "\n",
    "If there is enough requests I will endeavor to move to 1.10 in July 2019 as there are still many issues with the latest release.  This will cover the spectrum of Cuda 9 GPUS with compute capability 3.5+.  \n",
    "\n",
    "A future commitment with actual dates and version numbers?  Yes.  \n",
    "\n",
    "On linux Ubuntu, any old machine had Python and cmake already so setup was super easy with 1.5.0.  Mac with xcode etc from Yosemite to Sierra - Easy enough and under a gig for xcode and everything.\n",
    "\n",
    "I wish somebody had told me these things...\n",
    "Tensorflow 1.5.0 is the only version that currently works on all platforms without building from source\n",
    "You can just use show_labels=False in the demo/tutorial code and avoid any protoc or compiling (No labels)\n",
    "You can just add a category index to get the category names and therefore avoid any compiling\n",
    "Only need pycocotools for eval if use pngs or json\n",
    "\n",
    "All code is compatible with previous versions so simply point to the new version of slim and object detection and go.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuck?\n",
    "\n",
    "Please contact me if you are:\n",
    "A researcher who just wants to identify and count from images\n",
    "I am looking for feedback from the setup and the codecs\n",
    "Please tell me if you succeed as sometimes it is only those that fail.\n",
    "\n",
    "Students and Personal use\n",
    "Try google and stackoverflow.  Please help each other and I try to fix any bugs and implement community consensus.\n",
    "\n",
    "Experienced users\n",
    "I can't keep on top of all the changes accross all-platforms and all versions of TF and OD.  If you have an easier setup\n",
    "\n",
    "If you know more than me please tell me.  I am still not entirely happy with everything\n",
    "I have been testing for 1.10 and still too many bugs. \n",
    "The only things that have really changed from an outsiders perspective is:\n",
    "    you now either have to go back to a previous commit on github or move the train.py back out of the legacy folder etc\n",
    "    you now either cannot use 1.5.1+ or 1.7+ due to OS, 32-bit or AVX issues\n",
    "    cannot get the drivers working despite RC3\n",
    "    have issues with Visual Studio update vs standalone drivers\n",
    "    Some would have to build from source and that is 'too hard'\n",
    "I am only supporting TF 1.5.0 until some bugs have better solutions.  \n",
    "If anyone has a cross-platform solution and binaries for 1.10 I will migrate.  \n",
    "As it is, 1.10 offers little for a researcher as will work with latest models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
