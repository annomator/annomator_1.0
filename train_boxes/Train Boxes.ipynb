{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "### 1 Create tf record files\n",
    "### 2 Train\n",
    "### 3 Export Graph\n",
    "### 4 Detect and ouput results\n",
    "\n",
    "##### 4 Should be Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to code\n",
    "#import os, sys\n",
    "#PATH_TO_TF_SLIM = os.path.join(os.path.abspath('./'), 'tf_slim')\n",
    "#sys.path.append(PATH_TO_TF_SLIM)\n",
    "# Still need to run from terminal etc\n",
    "# Run in terminal from train dir (the jupyter terminal)\n",
    "#! export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/tf_slim\n",
    "! export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/tf_slim_obj_det\n",
    "set PYTHONPATH=%PYTHONPATH%; C:\\Users\\Arend\\Desktop\\Tensorflow\\Projects\\annotator\\annomate\\tf_slim_obj_det\n",
    "# ref\n",
    "#! export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`../code\n",
    "#! export PYTHONPATH=/tf_slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Create TF Record files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking json 10000 0.232 seconds\n",
      "Checking json 20000 0.482 seconds\n",
      "Checking json 30000 0.706 seconds\n",
      "Checking json 40000 0.930 seconds\n",
      "Checking json 50000 1.140 seconds\n",
      "Checking json 60000 1.355 seconds\n",
      "Checking json 70000 1.569 seconds\n",
      "Checking json 80000 1.784 seconds\n",
      "Checking json 90000 2.005 seconds\n",
      "Checking json 100000 2.225 seconds\n",
      "Checking json 110000 2.444 seconds\n",
      "106459 training and 11828 validation images\n",
      "Writing train.record\n",
      "1 person 1000\n",
      "16 bird 107\n",
      "17 cat 49\n",
      "18 dog 49\n",
      "Images 1000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 237\n",
      "17 cat 93\n",
      "18 dog 116\n",
      "Images 2000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 426\n",
      "17 cat 121\n",
      "18 dog 143\n",
      "Images 3000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 480\n",
      "17 cat 171\n",
      "18 dog 194\n",
      "Images 4000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 554\n",
      "17 cat 192\n",
      "18 dog 229\n",
      "Images 5000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 665\n",
      "17 cat 237\n",
      "18 dog 268\n",
      "Images 6000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 753\n",
      "17 cat 265\n",
      "18 dog 300\n",
      "Images 7000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 845\n",
      "17 cat 326\n",
      "18 dog 333\n",
      "Images 8000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 896\n",
      "17 cat 369\n",
      "18 dog 378\n",
      "Images 9000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 988\n",
      "17 cat 400\n",
      "18 dog 423\n",
      "Images 10000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 420\n",
      "18 dog 476\n",
      "Images 11000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 482\n",
      "18 dog 524\n",
      "Images 12000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 526\n",
      "18 dog 643\n",
      "Images 13000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 558\n",
      "18 dog 678\n",
      "Images 14000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 589\n",
      "18 dog 714\n",
      "Images 15000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 636\n",
      "18 dog 766\n",
      "Images 16000 Average 0.029 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 666\n",
      "18 dog 804\n",
      "Images 17000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 709\n",
      "18 dog 842\n",
      "Images 18000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 759\n",
      "18 dog 895\n",
      "Images 19000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 805\n",
      "18 dog 957\n",
      "Images 20000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 876\n",
      "18 dog 986\n",
      "Images 21000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 912\n",
      "18 dog 1000\n",
      "Images 22000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 948\n",
      "18 dog 1000\n",
      "Images 23000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 998\n",
      "18 dog 1000\n",
      "Images 24000 Average 0.028 seconds\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 1000\n",
      "18 dog 1000\n",
      "Category sampling complete - quoto achieved\n",
      "--------------------------------------------------\n",
      "1 person 1000\n",
      "16 bird 1000\n",
      "17 cat 1000\n",
      "18 dog 1000\n",
      "22064 images skipped as no annotations to add\n",
      "167013 annotations skipped due to sampling\n",
      "Processed 24152 images and 0 masks\n",
      "Total Images to TF Record File 2088\n",
      "--------------------------------------------------\n",
      "Writing val.record\n",
      "1 person 100\n",
      "16 bird 100\n",
      "17 cat 49\n",
      "18 dog 49\n",
      "Images 1000 Average 0.029 seconds\n",
      "1 person 100\n",
      "16 bird 100\n",
      "17 cat 93\n",
      "18 dog 100\n",
      "Images 2000 Average 0.029 seconds\n",
      "1 person 100\n",
      "16 bird 100\n",
      "17 cat 100\n",
      "18 dog 100\n",
      "Category sampling complete - quoto achieved\n",
      "--------------------------------------------------\n",
      "1 person 100\n",
      "16 bird 100\n",
      "17 cat 100\n",
      "18 dog 100\n",
      "1910 images skipped as no annotations to add\n",
      "13984 annotations skipped due to sampling\n",
      "Processed 2130 images and 0 masks\n",
      "Total Images to TF Record File 220\n",
      "--------------------------------------------------\n",
      "Finished 12 mins 42 secs\n",
      "Images skipped as no image found for json reference 0\n",
      "2088 train images 220 validation images\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create TF Record files required for training\n",
    "#! python create_coco_coded100_tf_record.py \\\n",
    "\n",
    "! python create_tf_record_from_json.py\n",
    "\n",
    "\n",
    "\n",
    "# Default\n",
    "#--image_dir=./train_images \\\n",
    "#--mask_dir=./train_masks \\\n",
    "#--output_dir=./tf_records \\\n",
    "#--val_split=0\n",
    "\n",
    "\n",
    "#--faces_only=False --mask_type=png\n",
    "\n",
    "# --data_dir=`pwd` --output_dir=`pwd` \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_generator.proto\n",
    "argmax_matcher.proto\n",
    "bipartite_matcher.proto\n",
    "box_coder.proto\n",
    "box_predictor.proto\n",
    "eval.proto\n",
    "faster_rcnn.proto\n",
    "faster_rcnn_box_coder.proto\n",
    "graph_rewriter.proto\n",
    "grid_anchor_generator.proto\n",
    "hyperparams.proto\n",
    "image_resizer.proto\n",
    "input_reader.proto\n",
    "keypoint_box_coder.proto\n",
    "losses.proto\n",
    "matcher.proto\n",
    "mean_stddev_box_coder.proto\n",
    "model.proto\n",
    "multiscale_anchor_generator.proto\n",
    "optimizer.proto\n",
    "pipeline.proto\n",
    "post_processing.proto\n",
    "preprocessor.proto\n",
    "region_similarity_calculator.proto\n",
    "square_box_coder.proto\n",
    "ssd.proto\n",
    "ssd_anchor_generator.proto\n",
    "string_int_label_map.proto\n",
    "train.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\argmax_matcher.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\bipartite_matcher.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\box_coder.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\box_predictor.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\eval.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\faster_rcnn.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\faster_rcnn_box_coder.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\graph_rewriter.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\grid_anchor_generator.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\hyperparams.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\image_resizer.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\input_reader.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\keypoint_box_coder.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\losses.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\matcher.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\mean_stddev_box_coder.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\model.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\multiscale_anchor_generator.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\optimizer.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\pipeline.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\post_processing.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\preprocessor.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\region_similarity_calculator.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\square_box_coder.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\ssd.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\ssd_anchor_generator.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\string_int_label_map.proto\n",
    "protoc --python_out=. .\\object_detection\\protos\\train.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arend\\Desktop\\Tensorflow\\Projects\\annotator\\annomate\\tf_slim_obj_det\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arend\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"../tf_slim_obj_det/object_detection/train.py\", line 49, in <module>\n",
      "    from object_detection import trainer\n",
      "ModuleNotFoundError: No module named 'object_detection'\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#import os, sys\n",
    "#OBJ_DET_PATH = os.path.abspath(os.path.join('..', 'tf_slim_obj_det'))\n",
    "#print(OBJ_DET_PATH)\n",
    "#sys.path.append(OBJ_DET_PATH)\n",
    "#! export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`../tf_slim_obj_det\n",
    "#! python ../tf_slim_obj_det/object_detection/train.py \\\n",
    "\n",
    "! python ../tf_slim_obj_det/object_detection/train.py \\\n",
    "--logtostderr \\\n",
    "--pipeline_config_path=pipeline.config \\\n",
    "--train_dir=tf_train\n",
    "\n",
    "#set PYTHONPATH=%PYTHONPATH%; C:\\Users\\Arend\\Desktop\\Tensorflow\\Projects\\annotator\\annomate\\tf_slim_obj_det\n",
    "#echo %PYTHONPATH%\n",
    "\n",
    "python ..\\tf_slim_obj_det\\object_detection\\train.py --logtostderr --pipeline_config_path=pipeline.config --train_dir=tf_train\n",
    "python ..\\..\\Scripts\\object_detection\\train.py --logtostderr --pipeline_config_path=pipeline.config --train_dir=tf_train\n",
    "# You can expect a few warnings at first - Scroll down to check\n",
    "\n",
    "# The following error usually means python path skipped (Top cell)\n",
    "# ModuleNotFoundError: No module named 'deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain\n",
    "##### Just need to alter one line in tf_train/pipeline.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following code does the same thing but uses notebook debugger\n",
    "# %run -i object_detection/train.py --logtostderr --pipeline_config_path=models/model/pipeline.config --train_dir=models/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the progress in a better format\n",
    "# Start a new terminal window and navigate to this directory\n",
    "# Enter: tensorboard --logdir='tf_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Export frozen graph for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/arend/tensorflow/Projects/coco_panoptic/tf_obj_det/tf_slim_obj_det/object_detection/exporter.py:358: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "Converted 410 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Export frozen graph for inference - update checkpoint number\n",
    "! python ../tf_slim_obj_det/object_detection/export_inference_graph.py \\\n",
    "--input_type image_tensor \\\n",
    "--pipeline_config_path tf_train/pipeline.config \\\n",
    "--trained_checkpoint_prefix tf_train/model.ckpt-2839 \\\n",
    "--output_directory exported_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Testing\n",
    "Copy the frozen inference graph to test/frozen_graph\n",
    "Run tiny tester notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
